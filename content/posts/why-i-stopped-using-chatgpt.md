+++
date = '2025-12-08T02:01:09Z'
draft = false
menus = 'content'
title = 'Why I stopped using ChatGPT (and why the hype is annoying)'
+++

### Disclaimer:
This is just my personal opinion. I am not trying to convince anyone, and I am not paid by any of these companies.

TL;DR: I prefer Gemini over GPT, but mostly think the AI hype is getting out of hand.

Everyone is talking about AI right now. OpenAI and their CEO are constantly in the news, and other companies like Google and Meta, even newer companies such as Mistral and Anthropic (at least in the AI scene) are trying to catch up. But because ChatGPT is the most popular, it has the most users and news about it whenever they do something.

My main issue with ChatGPT is that it tries too hard to please the user. It will agree with whatever you say, even if you are wrong. If you give it false info, it often just accepts it. When I used it in the early days, it hallucinated constantly, it knew how things worked in theory but failed completely in practice.

I also hated how OpenAI acted. They called themselves a "nonprofit" and "open" but refused to share their research and tried to monetize everything immediately after GPT-2.

I switched to Gemini because the free version of ChatGPT was getting extremely annoying. I realized that Gemini felt a bit different. Unlike ChatGPT, which acts like a "yes-man," Gemini actually argues with me at times. If I am wrong, it insists on its knowledge. I started using it for basic scripts and regex filters, and it felt more like a tool and less like a toy that could break at any time.

The newer Gemini models have improved a lot. It is fast, and unlike GPT, it stands by its values. If GPT sees a forbidden word, it gives a generic error. Gemini clearly refuses (compared to a hard generation stop) and explains why. It can be stubborn, but I prefer that over a model that lies to make me happy.

These days, I mostly use Gemini to help me understand how machine learning actually works on my local machine. I can show it error logs or data charts from my coding experiments, and it does a surprisingly good job of analyzing them. It helps me figure out if my code is broken or if the data is bad. However this does not mean it is perfect, saying a model is better than the other is almost as same as preferring a giant douche over a turd sandwich, it is meaningless.

I am still very skeptical about the industry. Big companies act like AI is magic that will replace humans and make infinite money. They are slapping the "AI" label on everything just to please investors. I hope these investors will eventually realize that replacing entire companies with chat bots is nothing more a fever dream.

AI is not magic. It has major flaws. As the internet fills up with AI-generated slop, these companies will struggle to find good data to train on. They will end up feeding their models their own garbage, like a snake eating its own tail.